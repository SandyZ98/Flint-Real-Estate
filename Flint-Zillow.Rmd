---
title: "Real estate values and the Flint water crisis"
author: "Ilse Paniagua and Zeping Tao"
date: "9/9/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(ZillowR)
library(censusapi)
library(tidyverse)
library(ggmap)
library(factoextra)
library(lubridate)
library(corrplot)
library(magrittr)
library(foreign)
library(XML)
library(tigris)
library(leaflet)
library(sf)
```

# Introduction

TBD


# Data Gathering

## Gathering Flint Census data (2010-2017)

```{r, eval=FALSE}
cs_key <- "MY KEY"
```

References:
https://hrecht.github.io/censusapi/articles/getting-started.html

```{r Available data census, cache=TRUE, eval=FALSE}

apis <- listCensusApis()
#View(apis)

```

We are interested in the American Community Survey 5-Year Data (2009-2017), name= acs/acs5

Metadata information from the American Community Survey 5-Year Data (2009-2017).

```{r, eval=FALSE}
#5 year detailed tables

ac5_vars <- listCensusMetadata(name = "acs/acs5", vintage=2017,
    type = "variables")

ac5_geo <- listCensusMetadata(name = "acs/acs5", vintage=2017,
    type = "geographies")

```
From the tables above we obtain the variables of interest:

```{r}
myvars <- c("B19001B_001E","B19001A_001E","B01001B_017E","B01001B_002E","B01001B_001E","B01001A_001E","B01001A_002E","B01001A_017E","B01001_027E","B01001_003E","B11016_002E","B11016_001E","B25107_001E")
```

Totals:

B19001B_001E: income for black households
B19001A_001E: income for white households
B01001B_017E: total female (black)
B01001B_002E: total male (black)
B01001B_001E: total black
B01001A_001E: total white
B01001A_002E: total male (white)
B01001A_017E: total female (white)
B01001_027E: female under 5 years
B01001_003E: male under 5 years
B11016_002E: family households (note: need to calculate proportion of family HH)
B11016_001E: total number of households
B25107_001E: median home value

B25034_010E: built 1940-1949
B25034_009E: built 1950-1959
B25034_008E: built 1960-1969
B25034_007E: built 1970-1979
B25034_006E: built 1980-1989
B25034_005E: built 1990-1999
B25034_004E: built 2000-2009

The state of Michigan is 026, and Genessee county is 049.

```{r, eval=FALSE}
#5 year detailed tables

#Variables that are only needed once (municipality names and housing structure age)

flint_strage <- getCensus(name = "acs/acs5", vintage = 2010,
vars = c("NAME","B25034_010E","B25034_009E","B25034_008E","B25034_007E","B25034_006E","B25034_005E","B25034_004E"),
region = "tract:*", regionin = "state:26+county:049", key = cs_key )

colnames(flint_strage) <- c("state","county","tract","desc","1940-1949","1950-1959","1960-1969","1970-1979","1980-1989","1990-1999","2000-2009")

glimpse(flint_strage)
```

Now we gather data for the years 2011-2017 for the variables that would change from year to year.
```{r, eval=FALSE}
#Loop for years 2010-2017
flint_acs5 <- matrix()

years <- c("2010","2011","2012","2013","2014","2015","2016","2017")

for(i in years){

flint_partial <- getCensus(name = "acs/acs5", vintage = i,
vars = myvars,
region = "tract:*", regionin = "state:26+county:049", key = cs_key )

colnames(flint_partial) <-c("state","county","tract","income_black","income_white","f_black","m_black","black","white","m_white","f_white","f_under5","m_under5","fam_hh","hh","homevalue")

#Male under 5: B18101_003E

flint_acs5 <- cbind(flint_acs5,flint_partial)
}

```

## Census Data Cleaning

We have 129 columns, some of which repeat across years. This step will help us organize variables for reshaping and will add clarity to variable names.

```{r Changing variable names, eval=FALSE}

#Removing empty first column
flint_acs5_clean <- flint_acs5[,2:129]

#Removing multiple cases of state and municipality ID
flint_acs5_clean <- flint_acs5_clean %>% select(-matches("state*|county*|tract*|desc*"))

#Adding years

#.1 = 2011, .2=2012.....7=2017

nums <- c(1,2,3,4,5,6,7)

for(col in colnames(flint_acs5_clean)){
  for(i in nums){
    colnames(flint_acs5_clean)[colnames(flint_acs5_clean) == col] <- gsub(paste("\\.", nums[i], sep = ""), paste("_201", nums[i], sep = ""), col)
  }
}

#Changing name of 2010 (col 1:13)

colnames(flint_acs5_clean)[1:13] <- paste(colnames(flint_acs5_clean[1:13]), "_2010",sep="")


#Adding structure age data
flint_acs5_clean <- cbind(flint_strage,flint_acs5_clean)

```

Now we will keep only the census tracts that are inside of Flint.

The census tracts of interest (39, obtained from Census website) are: 000100,001000,001100,001200,011713,013500,013600,001400,001500,001600,001700,001800,001900,000200,002000,002200,002300,002400,002600,002700, 002800,002900,000300,003000,003100,003200,003300,003400,003500,003600,003700,003800,000400,004000,000500,000600,000700,000800,000900

```{r, eval=FALSE}
#Keeping only tracts of interest
tracts <- (c(000100,001000,001100,001200,011713,013500,013600,001400,001500,001600,001700,001800,001900,000200,002000,002200,002300,002400,002600,002700, 002800,002900,000300,003000,003100,003200,003300,003400,003500,003600,003700,003800,000400,004000,000500,000600,000700,000800,000900))

#Full data
flint_acs5_clean$tract <- as.numeric(flint_acs5_clean$tract)

flint_acs5_clean <- flint_acs5_clean %>% filter(tract %in% tracts)

#Structure age data
flint_strage$tract <- as.numeric(flint_strage$tract)

flint_strage <- flint_strage %>% filter(tract %in% tracts)
```

## Restructure into tidy data

```{r, cache= TRUE, eval=FALSE}
#Gathering data

#Full dataset
flint_acs5_clean <- flint_acs5_clean %>%
  gather(5:11,key = "built", value = "cases") %>%
  arrange(.,tract)

#Structure age data
flint_strage <- 
  flint_strage %>%
  gather(5:11,key = "built", value = "cases") %>%
  arrange(.,tract)

#Creating year variable

flint_acs5_clean <- flint_acs5_clean  %>% select(noquote(order(colnames(.)))) %>% select(state,county,tract,desc,built,cases,everything())

#Reshaping data columns 7-110

acs_vars <- c("income_black","income_white","f_black","m_black","black","white","m_white","f_white","f_under5","m_under5","fam_hh","hh","homevalue") %>% sort(decreasing=FALSE)

flint_acs5_clean_full <- flint_acs5_clean %>% 
  reshape(
  idvar=c("tract","built"),
  varying=list(c(7:14),c(15:22),c(23:30),c(31:38),c(39:46),c(47:54),c(55:62),   c(63:70),c(71:78),c(79:86),c(87:94),c(95:102),c(103:110)),
  v.names=acs_vars, 
  timevar="year", 
  times=years, 
  direction="long") %>%
  arrange(.,tract)

glimpse(flint_acs5_clean_full)
```

Now we create a dataset with only one row per tract and year.

```{r, eval=FALSE}
#Dataset that doesn't include structure age

flint_acs5_series <- flint_acs5_clean_full %>%
  select(-built,-cases) %>%
  unique.data.frame()

glimpse(flint_acs5_series)

```

We now have three tidy datasets:

1. Housing structure age by tract (273 rows= 39 tracts* 7 structure age)
2. Demographic variables and housing structure by tract (2,184 rows= 39 tracts* 7 structure age * 8 years)
3. Demographic variables by tract (312 rows= 39 tracts * 8 years)

```{r}
#Reading saved data from census API calls.

load("Flint-Zillow.RData")

```

## Census Data Exploration

* Age of housing structures, by tract

Calcualte the total number of houses per tract. Then, calculate what percentage belong to each category, per tract. Aggregate the results in a bar chart for each age group.

```{r}
#Summary table, number of cases in each category

flint_strage %>%
  group_by(tract) %>% 
  mutate(numhouses=sum(cases)) %>%
  group_by(built,tract) %>%
  summarise(mean=cases/numhouses) %>%
  group_by(built) %>%
  summarise(proportion=mean(mean)) %>%
  ggplot(.,aes(built,proportion)) +
  geom_col() +
  theme_light() +
  labs(title= "Flint: Average age of housing structures")
                                    
```

Flint has a large proportion of old homes built between 1940-49, followed by homes built between 1960-69.

* Population trends over time

```{r}
flint_acs5_series$year <-  flint_acs5_series$year %>% as.numeric()
```

Population trends seem steady over time. The white population seems to have increased after 2017. This, combined with rising house prices in 2017, may point to some gentrification.


* Population trends over time

```{r}
#Changing year to numeric for time series
flint_acs5_series$year <-  flint_acs5_series$year %>% as.numeric()

#Adult males and females, by race
flint_acs5_series %>% 
  gather(6,8:10,15:18,key = "type", value = "population") %>%
  arrange(.,tract) %>% 
  filter(type %in% c("m_white","f_white","f_black","m_black","type","population")) %>%
  group_by(year, type) %>% summarise(mean=mean(population)) %>%
  ggplot(aes(x=year, y=mean)) + geom_area(aes(fill=type))
```

```{r}
#Income variable
flint_acs5_series %>% 
  gather(13:14,key = "race", value = "income") %>%
  arrange(.,tract) %>%
  group_by(year, race) %>%
  summarise(mean=mean(income)) %>%
  ggplot(aes(x=year, y=mean)) + geom_area(aes(fill=race))
```

* Number of children under 5

```{r}
#Children variable

flint_acs5_series %>%
  gather(6,8:10,15:18,key = "type", value = "population") %>%
  arrange(.,tract) %>%
  filter(type %in% c("m_under5","f_under5","type","population")) %>%
  group_by(year, type) %>%
  summarise(mean=mean(population)) %>%
  ggplot(aes(x=year, y=mean)) +
  geom_line(aes(color=type))

```

The average numer of children per tract declined slightly between 2013 and 2016.

* Trends in housing values over time

```{r}
#Housing values over time

flint_acs5_series$year <- flint_acs5_series$year %>% as.character()

flint_acs5_series %>% ggplot(., aes(x=year, y=homevalue)) + geom_point() + geom_boxplot()
```


## Gathering Zillow data 

"ZillowR" package provides funtions to call Zillow api to get its property data. However, it only allows specific addresses as input parameter. Therefore, we need to get all the addresses in Flint. Fortunately, TIGER/Line Shapefile provides the information that allows us to make up all the potential addresses in Flint and try them with Zillow api.
```{r cache=TRUE, eval=FALSE}

flint_acs5_series %>% gather(6,8:10,15:18,key = "type", value = "population") %>% 
  arrange(.,tract) %>% 
  filter(type %in% c("m_under5","f_under5","type","population")) %>%
  group_by(year, type) %>% 
  summarise(mean=mean(population)) %>% 
  ggplot(aes(x=year, y=mean)) + geom_line(aes(color=type))

#Changing year to character for individual box plots by year
flint_acs5_series$year <- flint_acs5_series$year %>% as.character()

flint_acs5_series %>% 
  ggplot(., aes(x=year, y=homevalue)) +
  geom_point() +
  geom_boxplot()
```


## Zillow API call

"ZillowR" package provides funtions to call Zillow api to get its property data. However, it only allows specific addresses as input parameter. Therefore, we need to get all the addresses in Flint. Fortunately, TIGER/Line Shapefile provides the information that allows us to make up all the potential addresses in Flint and try them with Zillow api.

First, we load the address ranges from "Address Ranges County-based Relationship File", which contains "Address range identifier"(ARID). Then we load the feature names (street names) from "Feature Names County-based Relationship File", which contains "Linear feature identifier"(LINEARID). Third, we load "Address Range-Feature Name County-based Relationship File" that describe the match between ARID and LINEARID.

```{r, cache=TRUE, eval=FALSE}

table_range<-read.dbf("Genesee County Address Range/tl_2019_26049_addr.dbf",as.is = TRUE)
table_names<-read.dbf("Genesee County Feature Names/tl_2019_26049_featnames.dbf",as.is=TRUE)
table_relat<-read.dbf("Genesee County Relationship File/tl_2019_26049_addrfn.dbf",as.is=TRUE)

table_ID <- merge(table_range,table_relat,by="ARID")
keep2<-c("ARID","LINEARID","FROMHN","TOHN","ZIP")
table_address <- merge(table_ID[keep2],unique(table_names[c("FULLNAME","LINEARID")]),by="LINEARID")

table_address$FROMHN<-as.numeric(table_address$FROMHN)
table_address$TOHN<-as.numeric(table_address$TOHN)
nrow(table_address[is.na(table_address$FROMHN),])
keep2<-c("FULLNAME","FROMHN","TOHN","ZIP")
table_addr_clean<-na.omit(unique(table_address[keep2]))

saveRDS(table_addr_clean,"Address Frame.RData")
```

Then, we set up the Zillow API keys. Since one Zillow API key only allows 1000 request per day, we registered 5 keys for a more efficient data gathering. We also set up a function to turn the "character(0)" and NULL value gathered into an "NA".
```{r, eval=FALSE}
zwsid<-c()
zwsid[1]<-'key 1'
zwsid[2]<-'key 2'
zwsid[3]<-'key 3'
zwsid[4]<-'key 4'
zwsid[5]<-'key 5'
z<-1

set_zillow_web_service_id(zwsid[z])
stop<-FALSE

EmptytoNA <- function(x){
  if(identical(x,character(0))||is.null(x)){
    x<-NA
  }
  return(x)
}

```

We randomly sample 250 records out of our 44,502 address frame per day and iterate them for API request. Although our daily sample may have overlapping records across days, our sampling rate is 0.5% (250 out of 44,502) so the overlapping records would be small enough to ignore. This method guarantteed the randomization and representativeness of our sample and bug tolerance. Even if we failed to extract data in a day and we start it over tommorrow, we can still get random sampled data with enough size.

```{r, cache=TRUE, eval=FALSE}
frame<-readRDS("Address Frame.RData")
set.seed(Sys.Date())
smp_frame<-sample_n(frame,250)
```

Then we set up the loop. The data extracted are turned into tibbles and they are merged into a tibble.
```{r, cache=TRUE, eval=FALSE, include=FALSE}

for(j in 1:nrow(smp_frame)){
  number<-seq(min(smp_frame$FROMHN[j],smp_frame$TOHN[j]),max(smp_frame$FROMHN[j],smp_frame$TOHN[j],by=2))
  table_zlw_j<-tibble()
  n<-1
  for(n in 1:length(number)){
    address<-paste(number[n],smp_frame$FULLNAME[j])
    Result<-GetDeepSearchResults(address, citystatezip = 'Flint, MI',rentzestimate=TRUE)
    if (Result$message$code==7&z==length(zwsid)){
      stop = TRUE
      break
    }
    if (Result$message$code==7){
      z<-z+1
      print(Result$message$text)
      set_zillow_web_service_id(zwsid[z])
    }
    if (Result$message$code==0){
      basic_info<-Result[["response"]][["results"]][["result"]]
      zpid<-basic_info[["zpid"]] %>% xmlValue()
      address_resp<-basic_info[["address"]][["street"]] %>% xmlValue()
      type<-basic_info[["useCode"]] %>% xmlValue()%>% EmptytoNA()
      taxAssessment<-basic_info[["taxAssessment"]] %>% xmlValue()%>% EmptytoNA()
      taxAssess_year<-basic_info[["taxAssessmentYear"]] %>% xmlValue()%>% EmptytoNA()
      yearBuilt<-basic_info[["yearBuilt"]] %>% xmlValue()%>% EmptytoNA()
      lotSizeSqFt<-basic_info[["lotSizeSqFt"]] %>% xmlValue()%>% EmptytoNA()
      finishedSqFt<-basic_info[["finishedSqFt"]] %>% xmlValue()%>% EmptytoNA()
      bathrooms<-basic_info[["bathrooms"]] %>% xmlValue()%>% EmptytoNA()
      bedrooms<-basic_info[["bedrooms"]] %>% xmlValue()%>% EmptytoNA()
      lastSoldDate<-basic_info[["lastSoldDate"]] %>% xmlValue()%>% EmptytoNA()
      lastSoldPrice<-basic_info[["lastSoldPrice"]] %>% xmlValue()%>% EmptytoNA()
      
      Zestimate_data<-Result[["response"]][["results"]][["result"]][["zestimate"]] 
      zestimate<-Zestimate_data[["amount"]] %>% xmlValue() %>% EmptytoNA()
      zest_last_updated<-Zestimate_data[["last-updated"]] %>% xmlValue() %>% EmptytoNA()
      zest_valueChange<-Zestimate_data[["valueChange"]] %>% xmlValue() %>% EmptytoNA()
      zest_upper_range<-Zestimate_data[["valuationRange"]][["high"]] %>% xmlValue() %>% EmptytoNA()
      zest_lower_range<-Zestimate_data[["valuationRange"]][["low"]] %>% xmlValue() %>% EmptytoNA()
      
      Rent_data<-Result[["response"]][["results"]][["result"]][["rentzestimate"]]
      rentzestimate<-Rent_data[["amount"]] %>% xmlValue() %>% EmptytoNA()
      rent_last_updated<-Rent_data[["last-updated"]] %>% xmlValue() %>% EmptytoNA()
      rent_valueChange<-Rent_data[["valueChange"]] %>% xmlValue() %>% EmptytoNA()
      rent_upper_range<-Rent_data[["valuationRange"]][["high"]] %>% xmlValue() %>% EmptytoNA()
      rent_lower_range<-Rent_data[["valuationRange"]][["low"]] %>% xmlValue() %>% EmptytoNA()
      
      Address_data<-Result[["response"]][["results"]][["result"]][["address"]]
      Lat<-Address_data[["latitude"]] %>% xmlValue() %>% EmptytoNA()
      Long<-Address_data[["longitude"]] %>% xmlValue() %>% EmptytoNA()
      
      table_zlw_temp<-tibble(address,address_resp<-as.character(address_resp),ZPID=as.numeric(zpid),type=as.character(type),taxAssessment=as.numeric(taxAssessment),
                             taxAssess_year=as.character(taxAssess_year),yearBuilt=as.numeric(yearBuilt),lotSizeSqFt=as.numeric(lotSizeSqFt),
                             finishedSqFt=as.numeric(finishedSqFt),bathrooms=as.numeric(bathrooms),bedrooms=as.numeric(bedrooms),
                             lastSoldPrice=as.numeric(lastSoldPrice),lastSoldDate=as.character(lastSoldDate),
                             zestimate=as.numeric(zestimate),zest_valueChange=as.numeric(zest_valueChange),
                             zest_upper_range=as.numeric(zest_upper_range),zest_lower_range=as.numeric(zest_lower_range),zest_last_updated=as.character(zest_last_updated),
                             rentzestimate=as.numeric(rentzestimate),rent_valueChange=as.numeric(rent_valueChange),
                             rent_upper_range=as.numeric(rent_upper_range),rent_lower_range=as.numeric(rent_lower_range),
                             rent_last_updated=as.character(rent_last_updated),
                             lat=as.character(Lat),long=as.character(Long),zip=as.character(smp_frame$ZIP[j]),download_date=Sys.Date())
      table_zlw_j<-rbind(table_zlw_j,table_zlw_temp)
    }
  }
  if (stop){break}
  table_zlw<-rbind(table_zlw,table_zlw_j)
  print(c(paste("z=",z),paste("j=",j),paste("nrow=",nrow(table_zlw))))
}

save.image(paste("Zillow data",Sys.Date,".Rdata"))
```

We gathered 9351 records in a tibble with 27 variables. We use the Zillow property ID(ZPID) to remove duplicates. We obtain 5843 unique records. 

```{r, eval=FALSE}
length(unique(table_zlw$ZPID))
  #5843
table_zlw_nondup<-table_zlw %>% 
  distinct(ZPID,.keep_all=TRUE)
saveRDS(table_zlw_nondup,"Zillow data with distinct ZPID.Rdata")
```


## Cleaning Zillow Data

```{r, eval=FALSE}
zillow <-readRDS("Zillow data with distinct ZPID.Rdata")
```

Here, we double-check that there are unique records in the dataset, covert long and lat to numeric, and convert dates from character to date format.

```{r}
#Keeping unique records of the df
zillow <- zillow[!duplicated(zillow[,c("ZPID")]),]

#Changing longitude and latitude as numeric.
zillow$lat %<>% as.numeric()
zillow$long %<>% as.numeric()

#Extract year from last sold date

zillow$lastSoldYear <- 
  zillow$lastSoldDate %>%
  str_extract_all("\\d{4}$") %>% 
  as.character()

```

We will use Zillow records in our analysis if:

1) Their most recent tax assessment is between 2010 and 2017 (use taxAssessment price)
2) Their last sale date is between 2010 and 2017 (use lastSalePrice)

When there is both tax assessment and house sales for the same property in different years, both will be used for analysis.

```{r}
#Saving records for analysis
years <- c("2010","2011","2012","2013","2014","2015","2016","2017")

zillow_analysis <- zillow %>% 
  filter(lastSoldYear %in% years | taxAssess_year %in% years)

```

We have 2,066 observations.

Linking Zillow addresses to census tracts based on lat and long.
```{r, eval=FALSE}
zillow_analysis$geo <- apply(zillow_analysis, 1 , function(row) call_geolocator_latlon(row['lat'], row['long'])) #geolocator will be used for leaflet mapping later

zillow_analysis$tract <- zillow_analysis$geo %>% 
  substr(8,11) %>% #subsetting string
  as.numeric()
```

Joining Zillow and ACS data
```{r, eval=FALSE}
#Inner join Zillow and ACS data
#Filter merged data just to records where there was a tax assessment or home sale

merged <- 
  inner_join(zillow_analysis, flint_acs5_series, by="tract") %>%
  filter(year==taxAssess_year | year==lastSoldYear)

#Which Zillow addresses are not on the ACS tract list?
anti_join(zillow_analysis, flint_acs5_series, by="tract")

```

We have 812 records that are in our years of interest and could be matched to a Flint census tract.

Creating categories for home values, by groups of 10k.

```{r, eval=FALSE}
#Home value categorical variable
homecats <- c(-Inf,10000,20000,30000,40000,50000,60000,70000,80000, Inf)

#ACS homevalue variable
merged %<>%
  mutate(homecat = cut(homevalue, breaks=homecats,labels=c("0-10","11-20","21-30","31-40","41-50","51-60","61-70","71-80","80andabove")))

#Zillow tax assessment variable
merged %<>%
  mutate(taxcat = cut(taxAssessment, breaks=homecats,labels=c("0-10","11-20","21-30","31-40","41-50","51-60","61-70","71-80","80andabove")))

#Zillow home sales variable
merged %<>%
  mutate(salevaluecat = cut(lastSoldPrice, breaks=homecats,labels=c("0-10","11-20","21-30","31-40","41-50","51-60","61-70","71-80","80andabove")))
```

# Research question 1: How have home prices changed over time?

We chart changes over time for all three categories (ACS value, tax value, home sale value) across all census tracts. We use the median (not mean) because of potential outliers in the data.

```{r}
merged %>%
  select(year, taxAssessment, lastSoldPrice, homevalue, zestimate) %>%
  gather(key = type, value = value, 2:5) %>%
  group_by(year, type) %>%
  summarise(median = median(value, na.rm = TRUE)) %>%
  ggplot(aes(x=year, y=median)) +
  geom_line(aes(color=type, group=type), size=2) +
  labs(title="Flint: Home values over time",
       x= "Year",
       y="Median home value",
       color="Type",
       caption="Source: ACS and Zillow") +
  theme_light()
  


```


# Research question 2: Do Zillow and ACS prices match?

Do ACS category and Zillow categories match, on average by census tract?

```{r}
#Match between tax assessment and ACS
merged %<>%
  mutate(match_tax = case_when(
  homecat==taxcat & year==taxAssess_year  ~ 1,
  homecat!=taxcat & year==taxAssess_year ~ 0))

#Last home sale
merged %<>%
  mutate(match_sale = case_when(
    homecat==salevaluecat & year==lastSoldYear  ~ 1,
    homecat!=salevaluecat & year==lastSoldYear ~ 0))
```


What is the average discrepancy between reported values and administrative records? We also include Zillow zestimates as a comparison (although it is unclear for which year these estimates were generated).

```{r}
merged %>% 
  mutate(match_diff_tax = homevalue - taxAssessment, match_diff_sale = homevalue - lastSoldPrice, zest_diff = homevalue - zestimate) %>%
  group_by(tract) %>%
  summarise(mean(match_diff_tax, na.rm=TRUE), mean(match_diff_sale, na.rm=TRUE), mean(zest_diff, na.rm=TRUE))

```
The average difference between ACS home values and Zillow tax assessments and home sale prices is upwards of 20K to 50k! It is not clear that Zestimates are more accurate. The difference is higher or lower than administrative records depending on the tract.


Summary table for average matches by census tract and number of records for each comparison.

```{r}
#Matches by tract
merged %>% 
  group_by(tract) %>%
  summarise(mean_tax = mean(na.omit(match_tax)),
            mean_sale = mean(na.omit(match_sale)),
            count_tax = sum(!is.na(match_tax)),
            count_sale = sum(!is.na(match_sale)))
```

Because we do not have enough records per tract to conduct a robust analysis, we will cluster observations using both Zillow and Census data and make comparisons across clusters instead of census tracts.

## Creating clusters

We will cluster variables based on:
bedrooms, bathrooms, finishedsqFt, rentzestimate, lat, long, black, white, fam_hh.

We need to rescale variables before the analysis.

```{r}
clusters <-
  merged %>%
  select(bedrooms, bathrooms, finishedSqFt, rentzestimate, lat, long, black, white, fam_hh) %>%
  mutate_all(scale)
```

Next, create the distance matrix of the cleaned data.

```{r}
hclust_d <- dist(clusters)
as.matrix(hclust_d)[1:10, 1:10]
```

This distance matrix can be used to cluster counties, e.g. using the ward method.

```{r}
#Using the Ward method
hc_ward <- hclust(hclust_d, method = "ward.D2")
```

Ploting the dendogram to find a reasonable number of clusters.

```{r}
#A solution with seven clusters seem to be a good fit

plot(hc_ward, main = "Ward", xlab = "", sub = "")

rect.hclust(hc_ward, 
            k = 5, 
            border = "red")
```
We will select a small number of clusters (5) in order to be able to aggregate records more fully.

```{r}
#Number of cases per cluser
merged %>% mutate(cluster = cutree(hc_ward, 5)) %>% group_by(cluster) %>% summarise(count = n())

#Adding cluster column
merged %<>% mutate(cluster = cutree(hc_ward, 5))
```

Clusters 9 and 10 contain observations that appear to be outliers (5 obs. total). These will not be used for the analysis.

Now we again calculate the differences in ACS home values and administrative records.

```{r}
#Matches by cluster
merged %>%
  mutate(match_diff_tax = homevalue - taxAssessment, match_diff_sale = homevalue - lastSoldPrice) %>%
  filter(!cluster %in% c(5)) %>%
  group_by(cluster) %>%
  summarise("Matches by Tax (%)" = mean((match_tax), na.rm=TRUE),
            "Matches by Sale Price (%)" = mean((match_sale), na.rm=TRUE),
            "Number of tax records" = sum(!is.na(match_tax)),
            "Number of sale records" = sum(!is.na(match_sale)),
            "Average difference - Tax" = mean(match_diff_tax, na.rm=TRUE),
            "Average difference - Sales" = mean(match_diff_sale, na.rm=TRUE))
```

We still observe very large differences between randomly sampled addresses that returned a Zillow record and ACS data!


# Research question 3: Change in home values in neighborhoods with lead tracts

References:
https://rpubs.com/ben_bellman/sf_tigris


## Mapping census tracts

Getting census tract files from tigris package and changing to a simpler sf format.

```{r, cache=TRUE, eval=FALSE}
gs_geo <- tracts(state = "MI", county = "Genesee")

gs_geo %<>%st_as_sf(ri)
```

Keep only polygons that are in Flint.

```{r}
flint_geo %<>%
  mutate(tract = as.numeric(TRACTCE))

test <- flint_geo %>%
  filter(tract %in% merged$tract) %>%
  select(tract, geometry)
```

Merging geometry with ACS dataset. We will use this dataset for visualization rather than the merged Zillow-ACS dataset because our analysis of home values did not show much variation using tax assessments and home sale price, wheras the ACS subjective home value question did.

```{r}
acs_geo <- full_join(flint_acs5_clean, test, by="tract")

#Every tract merged!
anti_join(test, flint_acs5_clean, by="tract")

#Converting to a simpler sf format for visualization
acs_geo <- st_as_sf(acs_geo)
```

Now visualizations! We will visualize the change in home values from 2013 to 2015, roughly when the Flint water crisis became public.
```{r, include=FALSE}
#Empty census tract polygons
st_geometry(acs_geo) %>% plot()
```

```{r}
acs_geo %>%
  mutate(home_change = homevalue_2013 - homevalue_2016) %>%
  select(home_change, geometry) %>%
  ggplot() +
  geom_sf(aes(fill=home_change)) +
  scale_fill_distiller(palette = "RdYlGn", direction=1) +
  theme_light() +
  labs(title = "Flint: Change in home values 2013-2016",
       caption="Source: American Community Survey",
       fill="Change in dollars")
  
```

```{r, include=FALSE}
#Figuring out why there are gaps in the map
flint_ids <- unique(merged$tract) 

geo_ids <- unique(flint_geo$tract)

flint_ids %in% geo_ids

#It looks like all tracts merged properly, we just don't have a geometry available for tract 13500.
```

```{r, eval=FALSE, include=FALSE}
leaflet() %>%
  addTiles() %>%
  addCircles(merged_geo, ~lat, ~long)
```

```{r, eval=FALSE, include=FALSE}
leaflet(flint_geo) %>%
  addTiles() %>%
  addPolygons()
```
